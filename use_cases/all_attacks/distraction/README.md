# Distraction Attacks

Attacks that use various distraction techniques like extremely long prompts or complex reasoning tasks to confuse the model and bypass its defenses.